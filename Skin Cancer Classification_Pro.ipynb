{"cells":[{"cell_type":"markdown","metadata":{"id":"aNakwfxVRevG"},"source":["MULTIPLE MODLES WITH TEST RESULTS\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1LaoCG3gHIcdOcLcDivkrzujhrT3x-YIH"},"executionInfo":{"elapsed":6166568,"status":"ok","timestamp":1740528834794,"user":{"displayName":"Alekhya Parimala","userId":"06471525904903185516"},"user_tz":360},"id":"dQifiIlYNxVE","outputId":"b7712403-2634-49fd-91fb-15aeed739427"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix\n","import itertools\n","\n","# ---------------------------\n","# Set seeds for reproducibility\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# ---------------------------\n","# Create a new output directory\n","output_dir = \"final_multimodel\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# ---------------------------\n","# Define dataset paths\n","# We have one training directory (which will be split for validation)\n","# and one test directory\n","train_dir = '/content/drive/MyDrive/skin_cancer_data/train'\n","test_dir  = '/content/drive/MyDrive/skin_cancer_data/test'\n","\n","# ---------------------------\n","# Image sizes for each model\n","IMG_SIZES = {\n","    'InceptionV3': (299, 299),\n","    'ResNet50': (224, 224),\n","    'VGG16': (224, 224),\n","    'EfficientNetB0': (224, 224)\n","}\n","\n","# ---------------------------\n","# Import model architectures and their respective preprocessing functions\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as resnet_preprocess\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess\n","from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input as efficientnet_preprocess\n","\n","# Define model configurations in a dictionary\n","MODEL_CONFIGS = {\n","    'InceptionV3': {\n","        'constructor': InceptionV3,\n","        'preprocess': inception_preprocess,\n","        'img_size': IMG_SIZES['InceptionV3']\n","    },\n","    'ResNet50': {\n","        'constructor': ResNet50,\n","        'preprocess': resnet_preprocess,\n","        'img_size': IMG_SIZES['ResNet50']\n","    },\n","    'VGG16': {\n","        'constructor': VGG16,\n","        'preprocess': vgg_preprocess,\n","        'img_size': IMG_SIZES['VGG16']\n","    },\n","    'EfficientNetB0': {\n","        'constructor': EfficientNetB0,\n","        'preprocess': efficientnet_preprocess,\n","        'img_size': IMG_SIZES['EfficientNetB0']\n","    }\n","}\n","\n","# ---------------------------\n","# Data augmentation and validation split for training\n","train_datagen = ImageDataGenerator(\n","    validation_split=0.2,  # Use 20% of training data for validation\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    brightness_range=(0.8, 1.2),\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# For testing, used minimal preprocessing\n","test_val_datagen = ImageDataGenerator()\n","\n","def get_data_generators(img_size, batch_size=32):\n","    target_size = img_size\n","    # Training generator using validation_split\n","    train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        class_mode='binary',  # Assumes two classes: \"Benign\" and \"Malignant\"\n","        subset='training',\n","        shuffle=True\n","    )\n","\n","    # Validation generator from the same training data\n","    val_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        class_mode='binary',\n","        subset='validation',\n","        shuffle=False\n","    )\n","\n","    # Test generator remains as before\n","    test_generator = test_val_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        class_mode='binary',\n","        shuffle=False\n","    )\n","\n","    return train_generator, val_generator, test_generator\n","\n","# ---------------------------\n","# Build model with a Lambda layer to apply model-specific preprocessing\n","def build_model(model_name, config):\n","    img_size = config['img_size']\n","    preprocess_func = config['preprocess']\n","    base_model = config['constructor'](weights='imagenet', include_top=False, input_shape=img_size + (3,))\n","\n","    base_model.trainable = False  # Freeze base model\n","\n","    inputs = Input(shape=img_size + (3,))\n","    x = Lambda(lambda img: preprocess_func(img))(inputs)\n","    x = base_model(x, training=False)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification\n","\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","# ---------------------------\n","# Utility function: Plot and save confusion matrix\n","def plot_confusion_matrix(cm, classes, model_name, save_path=None,\n","                          normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.figure(figsize=(5, 4))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(f'{model_name} - {title}')\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()\n","\n","    if save_path:\n","        plt.savefig(save_path)\n","    plt.show()\n","\n","# ---------------------------\n","# Utility function: Plot and save sample predictions for first 10 images\n","def plot_sample_predictions(model, test_generator, class_labels, model_name, num_images=10, save_path=None):\n","    test_generator.reset()\n","    x_test, y_test = next(test_generator)\n","    preds = model.predict(x_test)\n","    preds_labels = (preds > 0.5).astype(\"int32\").flatten()\n","\n","    plt.figure(figsize=(15, 5))\n","    for i in range(min(num_images, len(x_test))):\n","        plt.subplot(2, num_images // 2, i+1)\n","        plt.imshow(x_test[i].astype(\"uint8\"))\n","        true_label = class_labels[int(y_test[i])]\n","        pred_label = class_labels[preds_labels[i]]\n","        plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n","        plt.axis(\"off\")\n","    plt.tight_layout()\n","\n","    if save_path:\n","        plt.savefig(save_path)\n","    plt.show()\n","\n","# ---------------------------\n","# Main loop: Train and evaluate each model\n","results = {}\n","\n","for model_name, config in MODEL_CONFIGS.items():\n","    print(f\"\\n{'='*20}\\nTraining model: {model_name}\\n{'='*20}\")\n","\n","    # Get data generators for the model-specific image size (with validation split)\n","    train_gen, val_gen, test_gen = get_data_generators(config['img_size'], batch_size=32)\n","\n","    # Build and compile the model\n","    model = build_model(model_name, config)\n","    model.summary()\n","\n","    # Early stopping callback to optimize training\n","    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","    # Train the model (adjust epochs as needed)\n","    history = model.fit(\n","        train_gen,\n","        epochs=30,\n","        validation_data=val_gen,\n","        callbacks=[early_stop],\n","        verbose=1\n","    )\n","\n","    # Evaluate on the test set\n","    test_gen.reset()\n","    predictions = model.predict(test_gen, verbose=1)\n","    pred_labels = (predictions > 0.5).astype(\"int32\").flatten()\n","    true_labels = test_gen.classes\n","\n","    # Generate classification report\n","    class_indices = test_gen.class_indices\n","    class_labels = list(class_indices.keys())\n","    report = classification_report(true_labels, pred_labels, target_names=class_labels)\n","    print(f\"\\nClassification Report for {model_name}:\\n{report}\")\n","\n","    # Save classification report to file\n","    report_path = os.path.join(output_dir, f\"{model_name}_classification_report.txt\")\n","    with open(report_path, \"w\") as f:\n","        f.write(report)\n","\n","    # Plot and save confusion matrix\n","    cm = confusion_matrix(true_labels, pred_labels)\n","    cm_save_path = os.path.join(output_dir, f\"{model_name}_confusion_matrix.png\")\n","    plot_confusion_matrix(cm, classes=class_labels, model_name=model_name, save_path=cm_save_path)\n","\n","    # Plot and save sample predictions (first 10 images)\n","    sample_pred_path = os.path.join(output_dir, f\"{model_name}_sample_predictions.png\")\n","    print(f\"Sample predictions for {model_name}:\")\n","    plot_sample_predictions(model, test_gen, class_labels, model_name, num_images=10, save_path=sample_pred_path)\n","\n","    # Save history and results in the results dictionary\n","    results[model_name] = {\n","        'history': history.history,\n","        'classification_report': report,\n","        'confusion_matrix': cm\n","    }\n","\n","    # Optionally, save the trained model as well\n","    model_save_path = os.path.join(output_dir, f\"{model_name}_model.h5\")\n","    model.save(model_save_path)\n","\n","print(\"\\nTraining and evaluation complete for all models. All outputs are saved in the directory:\", output_dir)\n"]},{"cell_type":"code","source":["# Install git (usually pre-installed in Colab)\n","!apt-get install -y git\n","\n","# Configure git\n","!git config --global user.name \"alekhyaparimala09\"\n","!git config --global user.email \"alekhyaparimala09@gmail.com\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSo8fKCFUnEn","executionInfo":{"status":"ok","timestamp":1740544602200,"user_tz":360,"elapsed":3225,"user":{"displayName":"Alekhya Parimala","userId":"06471525904903185516"}},"outputId":"0e1adcd3-c86a-4063-9e35-c6f84516f31e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git is already the newest version (1:2.34.1-1ubuntu1.12).\n","0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# Move the downloaded notebook file into the cloned repository folder\n","shutil.move(\"Multiple models_Pro.ipynb\", \"/content/your-repository/your_notebook_name.ipynb\")\n"],"metadata":{"id":"1miJO7TbiuM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/alekhyaparimala09/Skin-Cancer-Classification.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJEufmfvlsBu","executionInfo":{"status":"ok","timestamp":1740545381749,"user_tz":360,"elapsed":517,"user":{"displayName":"Alekhya Parimala","userId":"06471525904903185516"}},"outputId":"906b77bf-adfa-4125-bc30-fbbf975f1a52"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Skin-Cancer-Classification'...\n","warning: You appear to have cloned an empty repository.\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# Copy the notebook into the cloned repository folder (instead of moving)\n","shutil.copy(\"/content/drive/MyDrive/Colab Notebooks/Skin Cancer Classification_Pro.ipynbSkin Cancer Classification_Pro.ipynb\", \"/content/Skin-Cancer-Classification/Skin Cancer Classification_Pro.ipynb\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"ZUGFQ3oQlsEY","executionInfo":{"status":"error","timestamp":1740545614222,"user_tz":360,"elapsed":79,"user":{"displayName":"Alekhya Parimala","userId":"06471525904903185516"}},"outputId":"40a1bce7-07d7-4c82-ab6c-6e21650cc79e"},"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Skin Cancer Classification_Pro.ipynb'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2ab0b5d433fc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Copy the notebook into the cloned repository folder (instead of moving)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skin Cancer Classification_Pro.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/Skin-Cancer-Classification/Skin Cancer Classification_Pro.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Skin Cancer Classification_Pro.ipynb'"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CwcUND-ompTy","executionInfo":{"status":"ok","timestamp":1740545629450,"user_tz":360,"elapsed":44,"user":{"displayName":"Alekhya Parimala","userId":"06471525904903185516"}},"outputId":"52aad28c-c574-4ae9-ae0f-6d7dc241b2f3"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"NkaB1Wo1mi4Y"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"1Mn4zqHF9HZxIvyicuPbdpR8AWdxQYCcV","authorship_tag":"ABX9TyOwtikGAeO1hctqYtzN3Vhv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}